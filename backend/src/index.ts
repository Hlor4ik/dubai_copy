import express from 'express';
import cors from 'cors';
import multer from 'multer';
import dotenv from 'dotenv';

import { DialogueContext } from './types/index.js';
import { transcribeAudio } from './services/sttService.js';
import { synthesizeSpeech } from './services/ttsService.js';
import { processDialogue, createInitialGreeting, streamProcessDialogue } from './services/dialogueService.js';
import { getApartmentById, searchApartments, formatApartmentForVoice } from './services/apartmentService.js';
import {
  startSession,
  updateSession,
  endSession,
  markLandingGenerated,
  getAllSessions,
} from './services/analyticsService.js';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors({
  origin: ['http://localhost:5173', 'https://dubai-copy-2.onrender.com'],
  credentials: true
}));
app.use(express.json());

// Multer –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ
const upload = multer({ storage: multer.memoryStorage() });

// In-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π
const dialogueContexts: Map<string, DialogueContext> = new Map();

// === API Routes ===

// –ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
app.post('/api/session/start', async (_req, res) => {
  try {
    const sessionId = uuidv4();
    const greeting = createInitialGreeting();

    const context: DialogueContext = {
      sessionId,
      params: {},
      shownApartments: [],
      messageHistory: [{ role: 'assistant', content: greeting }],
      startTime: Date.now(),
    };

    dialogueContexts.set(sessionId, context);
    startSession(sessionId);

    // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è
    const audioBuffer = await synthesizeSpeech(greeting);

    res.json({
      sessionId,
      greeting,
      audio: audioBuffer.toString('base64'),
    });
  } catch (error) {
    console.error('Error starting session:', error);
    res.status(500).json({ error: 'Failed to start session' });
  }
});

// –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
app.post('/api/chat/voice', upload.single('audio'), async (req, res) => {
  try {
    const sessionId = req.body.sessionId;
    const context = dialogueContexts.get(sessionId);

    if (!context) {
      return res.status(400).json({ error: 'Session not found' });
    }

    if (!req.file) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    // 1. STT - —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
    const userText = await transcribeAudio(req.file.buffer, `${sessionId}.webm`);
    console.log(`[STT] User said: ${userText}`);

    // 2. –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    context.messageHistory.push({ role: 'user', content: userText });

    // 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥
    const result = await processDialogue(userText, context);
    console.log(`[LLM] Response: ${result.response.substring(0, 100)}...`);
    console.log(`[LLM] Action: ${result.action}`);
    console.log(`[LLM] Apartment: ${result.apartment?.id || 'none'}`);

    // 4. –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    Object.entries(result.paramsUpdate).forEach(([key, value]) => {
      if (value !== null && value !== undefined) {
        (context.params as Record<string, unknown>)[key] = value;
      }
    });

    // –î–æ–±–∞–≤–ª—è–µ–º –∫–≤–∞—Ä—Ç–∏—Ä—É –≤ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è search/next)
    if (result.apartment && (result.action === 'search' || result.action === 'next')) {
      if (!context.shownApartments.includes(result.apartment.id)) {
        context.shownApartments.push(result.apartment.id);
      }
    }

    context.messageHistory.push({ role: 'assistant', content: result.response });
    updateSession(context);

    // 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ª–µ–Ω–¥–∏–Ω–≥ –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –∏–Ω—Ç–µ—Ä–µ—Å
    let landingUrl: string | undefined;
    if (result.action === 'confirm_interest') {
      // –ë–µ—Ä—ë–º –∫–≤–∞—Ä—Ç–∏—Ä—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–∫–∞–∑–∞–Ω–Ω—É—é
      const apartmentForLanding = result.apartment || 
        (context.shownApartments.length > 0 
          ? getApartmentById(context.shownApartments[context.shownApartments.length - 1])
          : undefined);
      
      if (apartmentForLanding) {
        const landingId = apartmentForLanding.id; // Use apartment ID directly
        context.selectedApartment = apartmentForLanding.id;
        markLandingGenerated(sessionId, apartmentForLanding.id);
        landingUrl = `/apartment/${landingId}`;
        console.log(`[LANDING] Generated: ${landingUrl} for apartment ${apartmentForLanding.id}`);
      } else {
        console.log(`[LANDING] No apartment to generate landing for`);
      }
    }

    // 6. TTS - —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    const audioBuffer = await synthesizeSpeech(result.response);

    res.json({
      userText,
      response: result.response,
      audio: audioBuffer.toString('base64'),
      action: result.action,
      apartment: result.apartment,
      landingUrl,
      params: context.params,
    });
  } catch (error) {
    console.error('Error processing voice:', error);
    res.status(500).json({ error: 'Failed to process voice message' });
  }
});

// Streaming endpoint: returns Server-Sent Events (SSE) with audio chunks (base64) as they are synthesized.
app.post('/api/chat/voice-stream', upload.single('audio'), async (req, res) => {
  try {
    const sessionId = req.body.sessionId;
    const context = dialogueContexts.get(sessionId);

    if (!context) {
      return res.status(400).json({ error: 'Session not found' });
    }

    if (!req.file) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    // 1. STT
    const userText = await transcribeAudio(req.file.buffer, `${sessionId}.webm`);
    console.log(`[STT STREAM] User said: ${userText}`);

    context.messageHistory.push({ role: 'user', content: userText });

    // Setup SSE
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
    });
    res.flushHeaders?.();

    // send helper
    const sendEvent = (event: string, data: string) => {
      res.write(`event: ${event}\n`);
      res.write(`data: ${data}\n\n`);
    };

    // Send immediate ACK message to give user feedback while LLM processes
    const ackMessages = [
      '–°–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é...',
      '–°–µ–∫—É–Ω–¥–æ—á–∫—É, –∏—â—É...',
      '–ü–æ–¥–æ–∂–¥–∏—Ç–µ, –ø–æ—Å–º–æ—Ç—Ä—é...',
      '–°–µ–π—á–∞—Å –ø–æ—Å–º–æ—Ç—Ä–∏–º...',
      '–£—Ç–æ—á–Ω—è—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...',
    ];
    const ack = ackMessages[Math.floor(Math.random() * ackMessages.length)];
    try {
      const ackAudio = await synthesizeSpeech(ack);
      sendEvent('audio', ackAudio.toString('base64'));
      console.log(`[STREAM] Sent ACK: "${ack}"`);
    } catch (e) {
      console.error('[STREAM] Failed to synthesize ACK:', e);
    }

    // Buffer tokens and synthesize on short phrase boundaries (~40 chars or punctuation)
    // to trigger TTS faster and start playback sooner
    let tokenBuffer = '';
    const MAX_BUFFER_LEN = 40; // characters per synthesis ‚Äî very aggressive for low latency
    const phraseRegex = /([.!?,])\s+/; // phrase boundary

    // Helper to synthesize and emit a phrase
    const synthesizeAndEmit = async (text: string) => {
      if (!text.trim()) return;
      try {
        const audioBuf = await synthesizeSpeech(text.trim());
        const b64 = audioBuf.toString('base64');
        sendEvent('audio', b64);
        console.log(`[STREAM TTS] Synthesized: "${text.trim().substring(0, 50)}..."`);
      } catch (e) {
        console.error('[STREAM TTS] synth failed', e);
        sendEvent('error', JSON.stringify({ message: 'tts_error' }));
      }
    };

    // Collect full LLM response first (no streaming to TTS yet)
    let llmBuffer = '';
    const onToken = async (token: string) => {
      llmBuffer += token;
    };

    // Local fast-path for common confirm_interest phrases (skip LLM if detected)
    const lowerText = userText.toLowerCase().trim();
    const lastShownId = context.shownApartments[context.shownApartments.length - 1];
    
    // Check for "start search now" when user has at least one parameter
    const hasParams = Object.keys(context.params).length > 0;
    console.log(`[STREAM] Local detector check: hasParams=${hasParams}, lastShownId=${lastShownId}, lowerText="${lowerText}"`);
    
    if (hasParams && !lastShownId && /^(–Ω–µ—Ç|–≤—Å—ë|–Ω–∞—á–∏–Ω–∞–π|–Ω–∞—á–Ω–∏|–∏—â–∏|–ø–æ–∫–∞–∂–∏|–¥–∞–≤–∞–π|–ø–æ–µ—Ö–∞–ª–∏|–≥–æ|–ø–æ–∏—Å–∫|–≤–∞—Ä–∏–∞–Ω—Ç—ã|–ø–æ–∫–∞–∑–∞—Ç—å)[,.\s!]?/i.test(lowerText)) {
      console.log('[STREAM] Local search trigger detected:', userText);
      const availableApartments = searchApartments(context.params, context.shownApartments);
      if (availableApartments.length > 0) {
        const apartment = availableApartments[0];
        if (!context.shownApartments.includes(apartment.id)) {
          context.shownApartments.push(apartment.id);
        }
        const textToSpeak = `–í–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç: ${formatApartmentForVoice(apartment)} –ù—Ä–∞–≤–∏—Ç—Å—è?`;
        await synthesizeAndEmit(textToSpeak);
        
        context.messageHistory.push({ role: 'assistant', content: textToSpeak });
        updateSession(context);
        
        sendEvent('done', JSON.stringify({
          response: textToSpeak,
          action: 'search',
          apartment,
          params: context.params,
        }));
        
        return res.end();
      } else {
        const textToSpeak = '–ü–æ —ç—Ç–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –Ω–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –£—Ç–æ—á–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å.';
        await synthesizeAndEmit(textToSpeak);
        
        context.messageHistory.push({ role: 'assistant', content: textToSpeak });
        updateSession(context);
        
        sendEvent('done', JSON.stringify({
          response: textToSpeak,
          action: 'none',
          params: context.params,
        }));
        
        return res.end();
      }
    }
    
    // Check for "–¥–∞", "–¥–∞ –ø–æ–∫–∞–∂–∏", "—Ö–æ—á—É —ç—Ç—É", etc. when apartment was just shown
    if (lastShownId && (/^–¥–∞(\s|$)|^(–Ω—É )?–¥–∞[,!\.]?\s*(–ø–æ–∫–∞–∂–∏|–ø–æ–∫–∞–∂|—ç—Ç—É|–µ—ë)?$|^–ø–æ–∫–∞–∂–∏\s+(–º–Ω–µ|–µ—ë|—ç—Ç—É)|^—Ö–æ—á—É\s+—ç—Ç—É|^–±–µ—Ä—É|^–ø–æ–¥—Ö–æ–¥–∏—Ç|^–Ω—Ä–∞–≤–∏—Ç—Å—è|^–æ—Ç–ª–∏—á–Ω–æ|^—Ö–æ—Ä–æ—à–æ$/i.test(lowerText))) {
      console.log('[STREAM] Local confirm_interest detected:', userText);
      const apartment = getApartmentById(lastShownId);
      if (apartment) {
        const textToSpeak = '–û—Ç–ª–∏—á–Ω–æ! –Ø —Å–æ–∑–¥–∞—é –¥–ª—è –≤–∞—Å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π. –°—Å—ã–ª–∫–∞ –ø–æ—è–≤–∏—Ç—Å—è –Ω–∞ —ç–∫—Ä–∞–Ω–µ.';
        await synthesizeAndEmit(textToSpeak);
        
        const landingId = apartment.id; // Use apartment ID directly
        context.selectedApartment = apartment.id;
        markLandingGenerated(sessionId, apartment.id);
        const landingUrl = `/apartment/${landingId}`;
        
        context.messageHistory.push({ role: 'assistant', content: textToSpeak });
        updateSession(context);
        
        sendEvent('done', JSON.stringify({
          response: textToSpeak,
          action: 'confirm_interest',
          apartment,
          landingUrl,
          params: context.params,
        }));
        
        return res.end();
      }
    }

    // Start streaming LLM -> buffer
    const { finalResponse, error } = await streamProcessDialogue(userText, context, onToken);

    // If stream failed, fall back to processDialogue
    if (error) {
      console.log('[STREAM] Falling back to non-streaming response');
      const result = await processDialogue(userText, context);
      
      Object.entries(result.paramsUpdate).forEach(([key, value]) => {
        if (value !== null && value !== undefined) {
          (context.params as Record<string, unknown>)[key] = value;
        }
      });
      
      if (result.apartment && (result.action === 'search' || result.action === 'next')) {
        if (!context.shownApartments.includes(result.apartment.id)) {
          context.shownApartments.push(result.apartment.id);
        }
      }
      
      context.messageHistory.push({ role: 'assistant', content: result.response });
      updateSession(context);
      
      let landingUrl: string | undefined;
      if (result.action === 'confirm_interest' && result.apartment) {
        const landingId = result.apartment.id; // Use apartment ID directly
        context.selectedApartment = result.apartment.id;
        markLandingGenerated(sessionId, result.apartment.id);
        landingUrl = `/apartment/${landingId}`;
      }
      
      const audioBuf = await synthesizeSpeech(result.response);
      sendEvent('audio', audioBuf.toString('base64'));
      sendEvent('done', JSON.stringify({ 
        response: result.response, 
        action: result.action,
        apartment: result.apartment,
        landingUrl,
        params: context.params,
      }));
      return res.end();
    }

    // Parse finalResponse JSON and apply dialogue logic
    console.log(`[STREAM] Raw finalResponse: "${finalResponse?.substring(0, 200) || ''}..."`);
    let parsed: any = undefined;
    try {
      parsed = JSON.parse(finalResponse || '');
    } catch {
      console.log(`[STREAM] Failed to parse JSON directly, trying regex match...`);
      const jsonMatch = (finalResponse || '').match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        console.log(`[STREAM] Found JSON match: "${jsonMatch[0].substring(0, 150)}..."`);
        try {
          parsed = JSON.parse(jsonMatch[0]);
        } catch {
          console.log(`[STREAM] Failed to parse JSON match`);
          parsed = undefined;
        }
      }
    }
    console.log(`[STREAM] Parsed result:`, parsed);

    let textToSpeak = '';
    let action = 'none';
    let apartment: any = undefined;
    let landingUrl: string | undefined;

    if (parsed) {
      action = parsed.action || 'none';
      const paramsUpdate = parsed.params_update || {};

      console.log(`[STREAM] Parsed action: ${action}`);
      console.log(`[STREAM] Params update from LLM:`, JSON.stringify(paramsUpdate));
      console.log(`[STREAM] Context params before update:`, JSON.stringify(context.params));

      // Apply params update
      Object.entries(paramsUpdate).forEach(([key, value]) => {
        if (value !== null && value !== undefined) {
          (context.params as Record<string, unknown>)[key] = value;
        }
      });

      console.log(`[STREAM] Context params after update:`, JSON.stringify(context.params));

      // Handle actions
      if (action === 'confirm_interest') {
        console.log(`[STREAM] CONFIRM_INTEREST detected`);
        console.log(`[STREAM] Shown apartments:`, context.shownApartments);
        const lastShownApartmentId = context.shownApartments[context.shownApartments.length - 1];
        console.log(`[STREAM] Last shown apartment ID:`, lastShownApartmentId);
        if (lastShownApartmentId) {
          apartment = getApartmentById(lastShownApartmentId);
          console.log(`[STREAM] Got apartment by ID:`, apartment?.id, apartment?.district);
        } else {
          const results = searchApartments(context.params, context.shownApartments);
          if (results.length > 0) {
            apartment = results[0];
          } else {
            action = 'none';
            textToSpeak = '–Ø –ø–æ–∫–∞ –Ω–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–≤–∞—Ä—Ç–∏—Ä—É. –£—Ç–æ—á–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.';
          }
        }

        if (apartment && !textToSpeak) {
          console.log(`[STREAM] Generating landing for apartment:`, apartment.id);
          textToSpeak = '–û—Ç–ª–∏—á–Ω–æ! –Ø —Å–æ–∑–¥–∞—é –¥–ª—è –≤–∞—Å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π. –°—Å—ã–ª–∫–∞ –ø–æ—è–≤–∏—Ç—Å—è –Ω–∞ —ç–∫—Ä–∞–Ω–µ.';
          const landingId = apartment.id; // Use apartment ID directly
          console.log(`[STREAM] Landing ID (apartment.id):`, landingId);
          console.log(`[STREAM] Landing stored, landingUrl:`, `/apartment/${landingId}`);
          context.selectedApartment = apartment.id;
          markLandingGenerated(sessionId, apartment.id);
          landingUrl = `/apartment/${landingId}`;
          console.log(`[STREAM] Landing URL ready for SSE:`, landingUrl);
        } else {
          console.log(`[STREAM] confirm_interest but apartment is null or textToSpeak already set`);
        }
      } else if (action === 'search' || action === 'next') {
        console.log(`[STREAM] Searching with params:`, JSON.stringify(context.params));
        console.log(`[STREAM] Already shown apartments:`, context.shownApartments);
        const results = searchApartments(context.params, context.shownApartments);
        console.log(`[STREAM] Search returned ${results.length} apartments`);
        if (results.length > 0) {
          apartment = results[0];
          console.log(`[STREAM] Selected apartment:`, apartment.id, apartment.district);
          if (!context.shownApartments.includes(apartment.id)) {
            context.shownApartments.push(apartment.id);
          }
          textToSpeak = `–í–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç: ${formatApartmentForVoice(apartment)} –ù—Ä–∞–≤–∏—Ç—Å—è?`;
        } else {
          action = 'none';
          textToSpeak = '–ü–æ —ç—Ç–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –Ω–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ß—Ç–æ –∏–∑–º–µ–Ω–∏–º?';
        }
      } else {
        textToSpeak = parsed.response || '';
      }
    } else {
      textToSpeak = finalResponse || '–ò–∑–≤–∏–Ω–∏—Ç–µ, –æ—à–∏–±–∫–∞.';
    }

    // Now stream the processed text to TTS in phrases
    console.log(`[STREAM] Final text to speak: "${textToSpeak.substring(0, 100)}..."`);
    let ttsBuffer = textToSpeak;
    
    while (ttsBuffer.length > 0) {
      const phraseMatch = ttsBuffer.match(phraseRegex);
      if (phraseMatch) {
        const endIdx = ttsBuffer.indexOf(phraseMatch[0]) + phraseMatch[0].length;
        const phrase = ttsBuffer.substring(0, endIdx);
        ttsBuffer = ttsBuffer.substring(endIdx);
        await synthesizeAndEmit(phrase);
      } else if (ttsBuffer.length >= MAX_BUFFER_LEN) {
        const lastSpace = ttsBuffer.lastIndexOf(' ', MAX_BUFFER_LEN);
        const cutPoint = lastSpace > MAX_BUFFER_LEN / 2 ? lastSpace : MAX_BUFFER_LEN;
        const phrase = ttsBuffer.substring(0, cutPoint);
        ttsBuffer = ttsBuffer.substring(cutPoint).trim();
        await synthesizeAndEmit(phrase);
      } else {
        await synthesizeAndEmit(ttsBuffer);
        break;
      }
    }

    // Update context
    context.messageHistory.push({ role: 'assistant', content: textToSpeak });
    updateSession(context);

    // Send done
    sendEvent('done', JSON.stringify({
      response: textToSpeak,
      action,
      apartment,
      landingUrl,
      params: context.params,
    }));

    return res.end();
  } catch (error) {
    console.error('Error processing voice stream:', error);
    res.status(500).json({ error: 'Failed to process voice stream' });
  }
});

// –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–≤–∞—Ä—Ç–∏—Ä—ã –¥–ª—è –ª–µ–Ω–¥–∏–Ω–≥–∞
app.get('/api/apartment/:landingId', (req, res) => {
  // landingId —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –∏ –µ—Å—Ç—å apartmentId
  const apartmentId = req.params.landingId;
  const apartment = getApartmentById(apartmentId);
  
  if (!apartment) {
    return res.status(404).json({ error: 'Apartment not found' });
  }

  res.json(apartment);
});

// –ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ—Å—Å–∏—é
app.post('/api/session/end', (req, res) => {
  const { sessionId } = req.body;
  const analytics = endSession(sessionId);
  dialogueContexts.delete(sessionId);
  
  res.json({ success: true, analytics });
});

// –ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É (–¥–ª—è –∞–¥–º–∏–Ω–∞)
app.get('/api/analytics', (_req, res) => {
  res.json(getAllSessions());
});

// –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
app.listen(PORT, () => {
  console.log(`üöÄ Server running on http://localhost:${PORT}`);
  console.log(`üìä Analytics available at http://localhost:${PORT}/api/analytics`);
});
